min_version: 5.21
description: |
  This is a template for live vector search testing.
  Key parameters:
   trainsize: TEMPLATE(trainsize)
   testsize: TEMPLATE(testsize)
   source_model: TEMPLATE(other)

  schema: Install the schema required to run the test
  rampup: Measure how long it takes to load a set of embeddings
  search_and_verify: Measure how the system responds to queries while it
   is indexing recently ingested data.
  #? await_index: Pause and wait for the system to complete compactions or index processing
  search: Run vector search with a set of default (or overridden) parameters
  search_and_rewrite: Run the same search operations as above, but while rewriting the data
  search_and_invalidate: Run the same search operations as above, but while overwriting the data
   with different content using the same vector id.
  In all of these phases, it is important to instance the metrics with distinct names.
  Also, aggregates of recall should include total aggregate as well as a moving average.

scenarios:

  default:
    # Remove any existing data
    drop: >-
      run tags='block:drop' threads===1 cycles===UNDEF
      errors=count

    # Install the schema required to run the test
    schema_ks: >-
      run tags='block:schema_ks' threads===1 cycles===UNDEF
    schema: >-
      run tags='block:schema' threads===1 cycles===UNDEF

    # Truncate any data before loading
    #    truncate: run tags='block:truncate' threads===1 cycles===UNDEF

    # Load training data, measure how long it takes to load
    rampup: >-
      run tags='block:rampup' threads=TEMPLATE(rampup_threads,auto)
      cycles===TEMPLATE(rampup_cycles,TEMPLATE(trainsize))
      errors=count,warn

    # Measure how the system responds to queries under a read only workload
    search_and_verify: >-
      run alias=search_and_verify tags='block:search_and_verify,optype=select'
      threads=TEMPLATE(search_threads,auto) cycles===TEMPLATE(search_cycles,TEMPLATE(testsize))
      errors=count,warn

    verify_recall: >-
      run alias=verify_recall tags='block:search_and_verify,optype=select'
      threads=TEMPLATE(search_threads,auto) cycles===TEMPLATE(search_cycles,TEMPLATE(testsize))
      errors=count,warn



  astra_vectors:

    # Remove any existing data
    drop: >-
      run tags='block:drop' threads===1 cycles===UNDEF
      errors=count

    # Install the schema required to run the test
    schema_ks: >-
      run tags='block:schema_ks' threads===1 cycles===UNDEF
    schema: >-
      run tags='block:schema' threads===1 cycles===UNDEF

    # Truncate any data before loading
#    truncate: run tags='block:truncate' threads===1 cycles===UNDEF

    # Load training data, measure how long it takes to load
    rampup: >-
      run tags='block:rampup' threads=TEMPLATE(rampup_threads,auto)
      cycles===TEMPLATE(rampup_cycles,TEMPLATE(trainsize))
      errors=count,warn

    # Measure how the system responds to queries under a read only workload
    search_and_verify: >-
      run alias=search_and_verify tags='block:search_and_verify,optype=select'
      threads=TEMPLATE(search_threads,auto) cycles===TEMPLATE(search_cycles,TEMPLATE(testsize))
      errors=count,warn

    verify_recall: >-
      run alias=verify_recall tags='block:search_and_verify,optype=select'
      threads=TEMPLATE(search_threads,auto) cycles===TEMPLATE(search_cycles,TEMPLATE(testsize))
      errors=count,warn

  astra_vectors_with_source_model:

    # Remove any existing data
    drop: >-
      run tags='block:drop' threads===1 cycles===UNDEF
      errors=count

    # Install the schema required to run the test
    schema: >-
      run tags='block:schema_with_source_model' threads===1 cycles===UNDEF

    # Truncate any data before loading
    #    truncate: run tags='block:truncate' threads===1 cycles===UNDEF

    # Load training data, measure how long it takes to load
    rampup: >-
      run tags='block:rampup' threads=TEMPLATE(rampup_threads,auto)
      cycles===TEMPLATE(rampup_cycles,TEMPLATE(trainsize))
      errors=count,warn

    # Measure how the system responds to queries under a read only workload
    search_and_verify: >-
      run alias=search_and_verify tags='block:search_and_verify,optype=select'
      threads=TEMPLATE(search_threads,auto) cycles===TEMPLATE(search_cycles,TEMPLATE(testsize))
      errors=count,warn

    verify_recall: >-
      run alias=verify_recall tags='block:search_and_verify,optype=select'
      threads=TEMPLATE(search_threads,auto) cycles===TEMPLATE(search_cycles,TEMPLATE(testsize))
      errors=count,warn

  astra_vectors_mixed_workload:
    # Measure how the system responds to queries while
    # it is indexing recently ingested data
    search_and_verify: >-
      run alias=search_and_verify tags='block:search_and_verify'
      cycles===TEMPLATE(search_cycles) errors=count,retry stride=100 striderate=7.50
      errors=counter threads=500

    # search_and_rewrite: run tags='block:search_and_rewrite'
    # search_and_invalidate: run tags='block:search_and_invalidate'

  optimize:
    # Remove any existing data
    drop: >-
      run tags='block:drop' threads===1 cycles===UNDEF
      errors=count

    # Install the schema required to run the test
    schema: >-
      run tags='block:schema' threads===1 cycles===UNDEF

    # Load training data, measure how long it takes to load
    rampup: >-
      run tags='block:rampup' threads=TEMPLATE(rampup_threads,auto)
      cycles===TEMPLATE(rampup_cycles,TEMPLATE(trainsize))
      errors=count,warn

    # Start the read only vectory query workload
    search_and_verify: >-
      start alias=search_and_verify tags='block:search_and_verify,optype=select'
      threads=TEMPLATE(search_threads,auto) cycles===TEMPLATE(search_cycles,TEMPLATE(testsize))
      errors=count,warn

    # Find the optimal rate for the search workload
    findmax: >-
      findmax activity=search_and_verify
      base_value=TEMPLATE(2000,findmax_base_rate)
      step_value=TEMPLATE(200,findmax_step_value)
      min_frames=TEMPLATE(10,findmax_min_frames)
      optimization_type=rate

    # Optimize the search workload
    optimo: >-
      optimo activity=search_and_verify
      startrate=${findmax.rate}
      sample_time_ms=1000

    # Retest the search workload with the optimized rate and thread count
    retest: >-
      reset activity=search_and_verify
      threads==${optimo.threads}
      rate==${optimo.rate}

params:
  driver: cqld4
  instrument: true

bindings:
  id: ToString()
  test_floatlist: HdfFileToFloatList("testdata/TEMPLATE(dataset).hdf5", "/test"); ToCqlVector();
  relevant_indices: HdfFileToIntArray("testdata/TEMPLATE(dataset).hdf5", "/neighbors")
  distance_floatlist: HdfFileToFloatList("testdata/TEMPLATE(dataset).hdf5", "/distances")
  train_floatlist: HdfFileToFloatList("testdata/TEMPLATE(dataset).hdf5", "/train"); ToCqlVector();
  synthetic_vectors: HashedFloatVectors(TEMPLATE(dimensions));

blocks:
  drop:
    params:
      cl: TEMPLATE(cl,LOCAL_QUORUM)
      prepared: false
      timeout: 600
    ops:
      drop_index: |
        DROP INDEX IF EXISTS TEMPLATE(keyspace,baselines).TEMPLATE(table,vectors)_value_idx;
      drop_table: |
        DROP TABLE IF EXISTS TEMPLATE(keyspace,baselines).TEMPLATE(table,vectors);
  truncate:
    params:
      cl: TEMPLATE(cl,LOCAL_QUORUM)
      prepared: false
      timeout: 600
    ops:
      truncate_table: |
        truncate TEMPLATE(keyspace,baselines).TEMPLATE(table,vectors);

  schema_ks:
    params:
      cl: TEMPLATE(cl,LOCAL_QUORUM)
      prepared: false
    ops:
      create_keyspace: |
        create keyspace if not exists TEMPLATE(keyspace,baselines)
        WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 'TEMPLATE(rf:1)'}
        AND durable_writes = true;

  schema:
    params:
      cl: TEMPLATE(cl,LOCAL_QUORUM)
      prepared: false
    ops:
      create_table: |
        CREATE TABLE IF NOT EXISTS TEMPLATE(keyspace,baselines).TEMPLATE(table,vectors) (
          key TEXT,
          value vector<float,TEMPLATE(dimensions)>,
          PRIMARY KEY (key)
        );
      create_sai_index: |
        CREATE CUSTOM INDEX IF NOT EXISTS ON TEMPLATE(keyspace,baselines).TEMPLATE(table,vectors) (value) USING 'StorageAttachedIndex'
        WITH OPTIONS = {'similarity_function' : 'TEMPLATE(similarity_function,cosine)'};
  schema_with_source_model:
    params:
      cl: TEMPLATE(cl,LOCAL_QUORUM)
      prepared: false
    ops:
      create_table: |
        CREATE TABLE IF NOT EXISTS TEMPLATE(keyspace,baselines).TEMPLATE(table,vectors) (
          key TEXT,
          value vector<float,TEMPLATE(dimensions)>,
          PRIMARY KEY (key)
        );
      create_sai_index: |
        CREATE CUSTOM INDEX IF NOT EXISTS ON TEMPLATE(keyspace,baselines).TEMPLATE(table,vectors) (value) USING 'StorageAttachedIndex'
        WITH OPTIONS = {'similarity_function' : 'TEMPLATE(similarity_function,cosine)', 'source_model' : 'TEMPLATE(source_model,other)'};
  rampup:
    params:
      cl: TEMPLATE(write_cl,LOCAL_QUORUM)
      prepared: true
    ops:
      insert: |
        INSERT INTO TEMPLATE(keyspace,baselines).TEMPLATE(table,vectors)
        (key, value) VALUES ({id},{train_floatlist});
  search_and_verify:
    ops:
      select_ann_limit_TEMPLATE(k,100):
        prepared: |
          SELECT * FROM TEMPLATE(keyspace,baselines).TEMPLATE(table,vectors)
          ORDER BY value ANN OF {test_floatlist} LIMIT TEMPLATE(select_limit,100);
        tags:
          optype: select
        verifier-init: |
          k=TEMPLATE(k,100)
          relevancy=new io.nosqlbench.nb.api.engine.metrics.wrappers.RelevancyMeasures(_parsed_op)
          relevancy.addFunction(io.nosqlbench.engine.extensions.computefunctions.RelevancyFunctions.recall("recall",k));
          relevancy.addFunction(io.nosqlbench.engine.extensions.computefunctions.RelevancyFunctions.precision("precision",k));
          relevancy.addFunction(io.nosqlbench.engine.extensions.computefunctions.RelevancyFunctions.F1("F1",k));
          relevancy.addFunction(io.nosqlbench.engine.extensions.computefunctions.RelevancyFunctions.reciprocal_rank("RR",k));
          relevancy.addFunction(io.nosqlbench.engine.extensions.computefunctions.RelevancyFunctions.average_precision("AP",k));
        verifier: |
          actual_indices=cql_utils.cqlStringColumnToIntArray("key",result);
          relevancy.accept({relevant_indices},actual_indices);
          return true;
      insert_rewrite:
        prepared: |
          INSERT INTO TEMPLATE(keyspace,baselines).TEMPLATE(table,vectors)
          (key, value) VALUES ({id},{train_floatlist});
        tags:
          optype: insert

  search_and_rewrite:
    ops:
      select_ann_limit:
        stmt: |
          SELECT * FROM TEMPLATE(keyspace,baselines).TEMPLATE(table,vectors) ORDER BY value ANN OF {test_vector} LIMIT TEMPLATE(select_limit,100);
        verifier-init: |
          scriptingmetrics.newSummaryGauge(_parsed_op,"recall")
#        verifier: |
      upsert_same:
        stmt: |
          INSERT INTO TEMPLATE(keyspace,baselines).TEMPLATE(table,vectors)
          (key, value) VALUES ({rw_key},{train_vector});
  search_and_invalidate:
    ops:
      select_ann_limit:
        stmt: |
          SELECT * FROM TEMPLATE(keyspace,baselines).TEMPLATE(table,vectors) ORDER BY value ANN OF {test_vector} LIMIT TEMPLATE(select_limit,100);
#        verifier-init: |
#        verifier: |
      upsert_random: |
        INSERT INTO TEMPLATE(keyspace,baselines).TEMPLATE(table,vectors)
        (key, value) VALUES ({rw_key},{train_vector});


